{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    }
   ],
   "source": [
    "corp=pd.read_csv(\"ner.csv\",encoding=\"ISO-8859-1\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word  ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of  ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators  ...   \n",
       "2       lowercase        marched      VBP  lowercase           have  ...   \n",
       "3       lowercase        through      VBN  lowercase        marched  ...   \n",
       "4     capitalized         London       IN  lowercase        through  ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"ner_dataset.csv\",encoding=\"ISO-8859-1\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d8bde7b431de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corp' is not defined"
     ]
    }
   ],
   "source": [
    "corp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing NER with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate NaN in first column\n",
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big data , cannot use it all\n",
    "data=data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(columns=[\"Sentence #\",\"Tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[\"Tag\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=np.unique(data[\"Tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes\n",
    "classes=classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=DictVectorizer(sparse=False)\n",
    "x = vectorizer.fit_transform(x.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6700, 2785), (3300, 2785))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-of-core Algorithms\n",
    "Here I use out of core algorithms because the data is too large and can't fit in my computer's memory at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1- Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  17 | elapsed:    0.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  17 | elapsed:    0.1s remaining:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1-- Epoch 1\n",
      "\n",
      "\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1-- Epoch 1Norm: 6.48, NNZs: 36, Bias: -2.000000, T: 6700, Avg. loss: 0.005075\n",
      "\n",
      "-- Epoch 1\n",
      "Total training time: 0.11 seconds.\n",
      "\n",
      "Norm: 19.70, NNZs: 209, Bias: -2.000000, T: 6700, Avg. loss: 0.038358\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1Norm: 4.47, NNZs: 17, Bias: -1.000000, T: 6700, Avg. loss: 0.001791\n",
      "\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 16.12, NNZs: 159, Bias: -3.000000, T: 6700, Avg. loss: 0.036119\n",
      "Total training time: 0.14 seconds.\n",
      "Norm: 4.24, NNZs: 10, Bias: -2.000000, T: 6700, Avg. loss: 0.001045\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 12.96, NNZs: 82, Bias: -1.000000, T: 6700, Avg. loss: 0.010448\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 16.06, NNZs: 151, Bias: -3.000000, T: 6700, Avg. loss: 0.023284\n",
      "Total training time: 0.16 seconds.\n",
      "Norm: 4.69, NNZs: 22, Bias: -2.000000, T: 6700, Avg. loss: 0.002985\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 14.63, NNZs: 137, Bias: -3.000000, T: 6700, Avg. loss: 0.020746\n",
      "Total training time: 0.15 seconds.\n",
      "Norm: 6.78, NNZs: 43, Bias: -2.000000, T: 6700, Avg. loss: 0.005672Norm: 5.66, NNZs: 24, Bias: -2.000000, T: 6700, Avg. loss: 0.003582\n",
      "Total training time: 0.11 seconds.\n",
      "\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 2.45, NNZs: 6, Bias: -2.000000, T: 6700, Avg. loss: 0.000149\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 17.32, NNZs: 173, Bias: -3.000000, T: 6700, Avg. loss: 0.027313\n",
      "Norm: 4.47, NNZs: 17, Bias: -2.000000, T: 6700, Avg. loss: 0.001791\n",
      "Total training time: 0.10 seconds.\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 13.64, NNZs: 129, Bias: -2.000000, T: 6700, Avg. loss: 0.022985\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 3.74, NNZs: 14, Bias: -1.000000, T: 6700, Avg. loss: 0.003134\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 18.60, NNZs: 190, Bias: 2.000000, T: 6700, Avg. loss: 0.027164\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  17 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  17 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  17 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=5, n_iter_no_change=5, n_jobs=-1,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "#Perceptron is like a NN with no hidden Layer\n",
    "#N_Jobs = -1 means using all processors\n",
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "#partial_fit ==> OOC algorithms\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to eliminate the O Class since it's the most common tag because it will make our results look much better than what they actually are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes=classes.copy()\n",
    "new_classes.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.04      1.00      0.08         9\n",
      "       B-eve       0.14      0.33      0.20         3\n",
      "       B-geo       1.00      0.03      0.06        69\n",
      "       B-gpe       0.69      0.62      0.65       102\n",
      "       B-nat       0.00      0.00      0.00         0\n",
      "       B-org       0.96      0.37      0.53        63\n",
      "       B-per       0.95      0.46      0.62        41\n",
      "       B-tim       0.64      0.96      0.77        52\n",
      "       I-art       0.00      0.00      0.00        10\n",
      "       I-eve       0.00      0.00      0.00         3\n",
      "       I-geo       0.00      0.00      0.00        11\n",
      "       I-gpe       1.00      0.17      0.29         6\n",
      "       I-nat       0.00      0.00      0.00         1\n",
      "       I-org       0.74      0.43      0.54        47\n",
      "       I-per       0.88      0.21      0.34        66\n",
      "       I-tim       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.42      0.41      0.42       487\n",
      "   macro avg       0.44      0.29      0.25       487\n",
      "weighted avg       0.76      0.41      0.45       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=per.predict(X_test),y_true=y_test,labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clearly see that our classifier hasn't been able to correctly separate all classes. The best classified class is B-tim with f1-score=0.77 , precision 0.64 and recall 0.96. In this project we are interested to get all entities and classify them well that's why a good model must have a good Precision,Recall and f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2- Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between Stochastic GD and GD :\n",
    "In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET (Mini-Batch SGD) of training sample from your training set to do the update for a parameter in a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       1.00      0.11      0.20         9\n",
      "       B-eve       0.00      0.00      0.00         3\n",
      "       B-geo       0.25      0.88      0.39        69\n",
      "       B-gpe       0.87      0.54      0.67       102\n",
      "       B-nat       0.00      0.00      0.00         0\n",
      "       B-org       0.88      0.33      0.48        63\n",
      "       B-per       0.61      0.61      0.61        41\n",
      "       B-tim       1.00      0.81      0.89        52\n",
      "       I-art       0.00      0.00      0.00        10\n",
      "       I-eve       0.50      0.33      0.40         3\n",
      "       I-geo       0.00      0.00      0.00        11\n",
      "       I-gpe       0.75      0.50      0.60         6\n",
      "       I-nat       0.00      0.00      0.00         1\n",
      "       I-org       0.89      0.17      0.29        47\n",
      "       I-per       0.86      0.18      0.30        66\n",
      "       I-tim       0.25      0.25      0.25         4\n",
      "\n",
      "   micro avg       0.51      0.47      0.49       487\n",
      "   macro avg       0.49      0.30      0.32       487\n",
      "weighted avg       0.72      0.47      0.49       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3- Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       1.00      0.22      0.36         9\n",
      "       B-eve       0.00      0.00      0.00         3\n",
      "       B-geo       0.28      0.77      0.41        69\n",
      "       B-gpe       0.45      0.72      0.55       102\n",
      "       B-nat       0.00      0.00      0.00         0\n",
      "       B-org       0.69      0.56      0.61        63\n",
      "       B-per       0.81      0.54      0.65        41\n",
      "       B-tim       0.96      0.87      0.91        52\n",
      "       I-art       0.00      0.00      0.00        10\n",
      "       I-eve       0.50      0.33      0.40         3\n",
      "       I-geo       0.75      0.27      0.40        11\n",
      "       I-gpe       0.29      0.33      0.31         6\n",
      "       I-nat       0.00      0.00      0.00         1\n",
      "       I-org       0.67      0.34      0.45        47\n",
      "       I-per       0.78      0.38      0.51        66\n",
      "       I-tim       0.09      0.50      0.15         4\n",
      "\n",
      "   micro avg       0.49      0.57      0.53       487\n",
      "   macro avg       0.45      0.36      0.36       487\n",
      "weighted avg       0.61      0.57      0.54       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4- Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passive: if correct classification, keep the model; Aggressive: if incorrect classification, update to adjust to this misclassified example, means that if the document is correctly classified, we keep in mind that it doesn't contain much information for updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pac =PassiveAggressiveClassifier()\n",
    "pac.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         9\n",
      "       B-eve       0.00      0.00      0.00         3\n",
      "       B-geo       0.23      0.90      0.37        69\n",
      "       B-gpe       0.92      0.55      0.69       102\n",
      "       B-nat       0.00      0.00      0.00         0\n",
      "       B-org       0.91      0.16      0.27        63\n",
      "       B-per       1.00      0.41      0.59        41\n",
      "       B-tim       0.90      0.88      0.89        52\n",
      "       I-art       0.00      0.00      0.00        10\n",
      "       I-eve       0.03      0.33      0.05         3\n",
      "       I-geo       0.00      0.00      0.00        11\n",
      "       I-gpe       1.00      0.17      0.29         6\n",
      "       I-nat       0.00      0.00      0.00         1\n",
      "       I-org       0.62      0.11      0.18        47\n",
      "       I-per       0.88      0.11      0.19        66\n",
      "       I-tim       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.44      0.42      0.43       487\n",
      "   macro avg       0.41      0.23      0.22       487\n",
      "weighted avg       0.71      0.42      0.42       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=pac.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on f1-score we can conclude that the Naive Bayes Multinomial classifier is the best one with an average of 0.53 \n",
    "(Ã  suivre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
